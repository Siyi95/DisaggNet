# NILM æ—¶åºæ•°æ®æ³„æ¼é˜²æŠ¤æœ€ä½³å®è·µä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

**æ˜¯çš„ï¼Œæ‚¨å¯ä»¥åŒæ—¶ä½¿ç”¨æ‰€æœ‰6ä¸ªé˜²æ³„æ¼æŠ€æœ¯ï¼** è¿™äº›æŠ€æœ¯æ˜¯äº’è¡¥çš„ï¼Œç»„åˆä½¿ç”¨èƒ½å¤Ÿæä¾›æœ€å¼ºçš„æ•°æ®æ³„æ¼é˜²æŠ¤æ•ˆæœã€‚

## ğŸ”’ 6å¤§æ ¸å¿ƒé˜²æ³„æ¼æŠ€æœ¯

### 1. Purged/Embargo Walk-Forward äº¤å‰éªŒè¯
**ä½œç”¨**ï¼šé˜²æ­¢æ—¶åºä¾èµ–æ³„æ¼
**å®ç°**ï¼šå†å²è®­ç»ƒ â†’ 24å°æ—¶ç¦è¿æœŸ â†’ æœªæ¥éªŒè¯

### 2. å…ˆåˆ†å‰²åé¢„å¤„ç†
**ä½œç”¨**ï¼šé˜²æ­¢æ ‡å‡†åŒ–æ³„æ¼
**å®ç°**ï¼šåªåœ¨è®­ç»ƒé›†ä¸Šè®¡ç®—StandardScalerå‚æ•°

### 3. éªŒè¯é›†éé‡å çª—å£
**ä½œç”¨**ï¼šé˜²æ­¢éªŒè¯é›†å†…éƒ¨ç›¸ä¼¼æ€§åç½®
**å®ç°**ï¼šstride = window_sizeï¼Œæœç»é‡å¤æ ·æœ¬

### 4. è®­ç»ƒé›†å°æ­¥é•¿é‡‡æ ·
**ä½œç”¨**ï¼šæ‰©å……æ ·æœ¬é‡æå‡å­¦ä¹ æ•ˆæœ
**å®ç°**ï¼šstride = 1ï¼Œæœ€å¤§åŒ–è®­ç»ƒæ•°æ®åˆ©ç”¨

### 5. æ ‡ç­¾/é˜ˆå€¼é˜²æ³„æ¼
**ä½œç”¨**ï¼šé˜²æ­¢é˜ˆå€¼è®¡ç®—æ³„æ¼
**å®ç°**ï¼šåªåœ¨è®­ç»ƒåˆ†ç‰‡ä¸Šä¼°è®¡ï¼ŒéªŒè¯åˆ†ç‰‡åªåº”ç”¨

### 6. ç‰¹å¾å·¥ç¨‹åˆ†ç‰‡å†…ç‹¬ç«‹
**ä½œç”¨**ï¼šé˜²æ­¢ç‰¹å¾ç»Ÿè®¡æ³„æ¼
**å®ç°**ï¼šæŒ‰foldå†…è®­ç»ƒæ®µä¼°è®¡å…¨å±€åˆ†å¸ƒç‰¹å¾

## ğŸš€ å®Œæ•´ä½¿ç”¨æ–¹å¼

### åŸºç¡€é…ç½®ï¼ˆåŒæ—¶å¯ç”¨æ‰€æœ‰æŠ€æœ¯ï¼‰

```python
from src.nilm_disaggregation.data.robust_dataset import RobustNILMDataModule
import pytorch_lightning as pl

# åˆ›å»ºæ•°æ®æ¨¡å— - è‡ªåŠ¨é›†æˆæ‰€æœ‰6ä¸ªé˜²æ³„æ¼æŠ€æœ¯
# ç°åœ¨ç»§æ‰¿PyTorch Lightningçš„LightningDataModule
data_module = RobustNILMDataModule(
    data_path='path/to/AMPds2.h5',
    sequence_length=64,
    batch_size=32,
    num_workers=4,
    
    # æŠ€æœ¯1: Purged/Embargo Walk-Forward
    cv_mode=True,              # å¯ç”¨Walk-Forwardäº¤å‰éªŒè¯
    current_fold=0,            # å½“å‰foldç´¢å¼•
    
    # æŠ€æœ¯3&4: å·®å¼‚åŒ–é‡‡æ ·ç­–ç•¥
    train_stride=1,            # è®­ç»ƒé›†å°æ­¥é•¿ï¼ˆæŠ€æœ¯4ï¼‰
    val_stride=64,             # éªŒè¯é›†éé‡å çª—å£ï¼ˆæŠ€æœ¯3ï¼‰
    
    # æŠ€æœ¯1&5&6: åˆ†å‰²å’Œé¢„å¤„ç†é…ç½®
    split_config={
        'embargo_hours': 24,       # 24å°æ—¶ç¦è¿æœŸ
        'purge_hours': 0,          # æ¸…æ´—æœŸ
        'cv_folds': 5,             # 5æŠ˜äº¤å‰éªŒè¯
        'min_train_hours': 30*24   # æœ€å°è®­ç»ƒé›†å¤§å°
    }
)

# æŠ€æœ¯2: å…ˆåˆ†å‰²åé¢„å¤„ç†ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰
data_module.setup('fit')  # è‡ªåŠ¨åº”ç”¨æŠ€æœ¯2ã€5ã€6

# ä¸PyTorch Lightning Traineræ— ç¼é›†æˆ
trainer = pl.Trainer(
    max_epochs=100,
    accelerator='auto',
    devices='auto'
)

# ç›´æ¥ä½¿ç”¨data_moduleè®­ç»ƒ
trainer.fit(model, datamodule=data_module)
```

### Walk-Forward äº¤å‰éªŒè¯ï¼ˆå®Œæ•´æµç¨‹ï¼‰

```python
import pytorch_lightning as pl
from src.nilm_disaggregation.data.robust_dataset import RobustNILMDataModule

# å®Œæ•´çš„5æŠ˜Walk-Forwardäº¤å‰éªŒè¯
results = []

# åˆ›å»ºæ•°æ®æ¨¡å—ï¼ˆå¯ç”¨äº¤å‰éªŒè¯æ¨¡å¼ï¼‰
data_module = RobustNILMDataModule(
    data_path='path/to/AMPds2.h5',
    cv_mode=True,
    train_stride=1,
    val_stride=64
)

for fold in range(5):
    print(f"\n=== Fold {fold + 1}/5 ===")
    
    # è®¾ç½®å½“å‰foldï¼ˆè‡ªåŠ¨åº”ç”¨æ‰€æœ‰6ä¸ªæŠ€æœ¯ï¼‰
    data_module.setup_fold(fold)
    
    # åˆ›å»ºæ¨¡å‹å’Œè®­ç»ƒå™¨
    model = YourNILMModel()
    trainer = pl.Trainer(
        max_epochs=50,
        accelerator='auto',
        devices='auto',
        logger=False,  # å¯é€‰ï¼šå…³é—­æ—¥å¿—ä»¥ç®€åŒ–è¾“å‡º
        enable_checkpointing=False  # å¯é€‰ï¼šå…³é—­æ£€æŸ¥ç‚¹
    )
    
    # è®­ç»ƒï¼ˆäº«å—æ‰€æœ‰é˜²æ³„æ¼ä¿æŠ¤ï¼‰
    trainer.fit(model, datamodule=data_module)
    
    # éªŒè¯
    val_results = trainer.validate(model, datamodule=data_module)
    results.append(val_results[0])  # Lightningè¿”å›åˆ—è¡¨
    
    print(f"Fold {fold + 1} éªŒè¯ç»“æœ: {val_results[0]}")

# è®¡ç®—äº¤å‰éªŒè¯å¹³å‡ç»“æœ
avg_results = calculate_cv_average(results)
print(f"\n5æŠ˜äº¤å‰éªŒè¯å¹³å‡ç»“æœ: {avg_results}")
```

### å•æ¬¡åˆ†å‰²æ¨¡å¼ï¼ˆå¿«é€Ÿå®éªŒï¼‰

```python
# å¦‚æœä¸éœ€è¦äº¤å‰éªŒè¯ï¼Œå¯ä»¥ä½¿ç”¨å•æ¬¡åˆ†å‰²
data_module = RobustNILMDataModule(
    data_path='path/to/AMPds2.h5',
    sequence_length=64,
    batch_size=32,
    cv_mode=False,             # å…³é—­äº¤å‰éªŒè¯
    train_stride=1,
    val_stride=64,
    split_config={
        'train_ratio': 0.7,
        'val_ratio': 0.15,
        'test_ratio': 0.15,
        'embargo_hours': 24        # ä»ç„¶ä¿æŒ24å°æ—¶é—´éš”
    }
)

data_module.setup('fit')
# ä»ç„¶äº«å—æŠ€æœ¯2ã€3ã€4ã€5ã€6çš„ä¿æŠ¤
```

## ğŸ“Š å½“å‰ä¼˜åŒ–çŠ¶æ€

### æ ‡ç­¾å¹³è¡¡æ€§ç°çŠ¶
- **å†°ç®±**: 50% âœ… (ç›®æ ‡: 35%-65%)
- **æ´—è¡£æœº**: 13.8% âš ï¸ (ç›®æ ‡: 15%-35%ï¼Œæ¥è¿‘ä¸‹é™)
- **å¾®æ³¢ç‚‰**: 3.1% âŒ (ç›®æ ‡: 8%-20%ï¼Œéœ€è¦ä¼˜åŒ–)
- **æ´—ç¢—æœº**: 16.9% âš ï¸ (ç›®æ ‡: 20%-40%ï¼Œæ¥è¿‘ä¸‹é™)

### æŠ€æœ¯åº”ç”¨çŠ¶æ€
âœ… **æŠ€æœ¯1**: Purged/Embargo Walk-Forward - å·²å®ç°  
âœ… **æŠ€æœ¯2**: å…ˆåˆ†å‰²åé¢„å¤„ç† - å·²å®ç°  
âœ… **æŠ€æœ¯3**: éªŒè¯é›†éé‡å çª—å£ - å·²å®ç°  
âœ… **æŠ€æœ¯4**: è®­ç»ƒé›†å°æ­¥é•¿é‡‡æ · - å·²å®ç°  
âœ… **æŠ€æœ¯5**: æ ‡ç­¾/é˜ˆå€¼é˜²æ³„æ¼ - å·²å®ç°  
âœ… **æŠ€æœ¯6**: ç‰¹å¾å·¥ç¨‹åˆ†ç‰‡å†…ç‹¬ç«‹ - å·²å®ç°  

## ğŸ”§ åç»­ä¼˜åŒ–å»ºè®®å®ç°

### 1. å¾®æ³¢ç‚‰æ£€æµ‹ä¼˜åŒ–

```python
# æ–¹æ¡ˆA: æ›´æ•æ„Ÿçš„é˜ˆå€¼ç­–ç•¥
def optimize_microwave_detection(power_data):
    # ä½¿ç”¨æ›´ä½çš„ç™¾åˆ†ä½æ•°
    sensitive_thresholds = [60, 65, 70, 75]  # é™ä½é˜ˆå€¼
    
    # ç»“åˆåŠŸç‡å˜åŒ–ç‡
    power_diff = np.diff(power_data)
    change_points = np.where(np.abs(power_diff) > np.std(power_diff) * 2)[0]
    
    # åœ¨å˜åŒ–ç‚¹é™„è¿‘å¯»æ‰¾å¾®æ³¢ç‚‰ä½¿ç”¨æ¨¡å¼
    for threshold_percentile in sensitive_thresholds:
        threshold = np.percentile(power_data, threshold_percentile)
        positive_ratio = np.mean(power_data > threshold)
        
        if 0.08 <= positive_ratio <= 0.20:
            return threshold
    
    # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºå˜åŒ–ç‚¹çš„åŠ¨æ€é˜ˆå€¼
    return np.percentile(power_data[change_points], 50)

# æ–¹æ¡ˆB: åˆæˆæ•°æ®å¢å¼º
def generate_microwave_synthetic_data(base_data, num_events=50):
    synthetic_data = base_data.copy()
    
    for _ in range(num_events):
        # éšæœºé€‰æ‹©æ’å…¥ä½ç½®
        start_idx = np.random.randint(0, len(synthetic_data) - 120)
        duration = np.random.randint(30, 120)  # 30ç§’åˆ°2åˆ†é’Ÿ
        
        # å¾®æ³¢ç‚‰åŠŸç‡æ¨¡å¼ï¼šå¿«é€Ÿä¸Šå‡ï¼Œå¹³ç¨³é«˜åŠŸç‡ï¼Œå¿«é€Ÿä¸‹é™
        power_profile = np.concatenate([
            np.linspace(0, 800, 5),      # å¿«é€Ÿä¸Šå‡
            np.full(duration-10, 800),   # å¹³ç¨³é«˜åŠŸç‡
            np.linspace(800, 0, 5)       # å¿«é€Ÿä¸‹é™
        ])
        
        # æ·»åŠ å™ªå£°
        power_profile += np.random.normal(0, 50, len(power_profile))
        
        # æ’å…¥åˆ°æ•°æ®ä¸­
        end_idx = start_idx + len(power_profile)
        if end_idx <= len(synthetic_data):
            synthetic_data[start_idx:end_idx] += power_profile
    
    return synthetic_data
```

### 2. åŠ¨æ€é˜ˆå€¼è°ƒæ•´

```python
class DynamicThresholdAdjuster:
    def __init__(self, target_ratios, adjustment_rate=0.1):
        self.target_ratios = target_ratios
        self.adjustment_rate = adjustment_rate
        self.current_thresholds = {}
    
    def adjust_thresholds(self, validation_results, appliance_data):
        """æ ¹æ®éªŒè¯æ€§èƒ½åŠ¨æ€è°ƒæ•´é˜ˆå€¼"""
        for appliance, (min_ratio, max_ratio) in self.target_ratios.items():
            current_f1 = validation_results.get(f'{appliance}_f1', 0)
            current_ratio = validation_results.get(f'{appliance}_positive_ratio', 0)
            
            # å¦‚æœF1åˆ†æ•°ä½ä¸”æ­£æ ·æœ¬æ¯”ä¾‹ä¸åœ¨ç›®æ ‡èŒƒå›´å†…
            if current_f1 < 0.5 and not (min_ratio <= current_ratio <= max_ratio):
                current_threshold = self.current_thresholds.get(appliance, 0)
                
                if current_ratio < min_ratio:
                    # æ­£æ ·æœ¬å¤ªå°‘ï¼Œé™ä½é˜ˆå€¼
                    new_threshold = current_threshold * (1 - self.adjustment_rate)
                elif current_ratio > max_ratio:
                    # æ­£æ ·æœ¬å¤ªå¤šï¼Œæé«˜é˜ˆå€¼
                    new_threshold = current_threshold * (1 + self.adjustment_rate)
                
                self.current_thresholds[appliance] = new_threshold
                print(f"è°ƒæ•´{appliance}é˜ˆå€¼: {current_threshold:.4f} -> {new_threshold:.4f}")
    
    def get_adjusted_thresholds(self):
        return self.current_thresholds.copy()
```

### 3. å¤šæ¨¡æ€ç‰¹å¾é›†æˆ

```python
class MultiModalFeatureExtractor:
    def extract_features(self, power_sequence):
        features = {}
        
        # æ—¶åŸŸç‰¹å¾
        features['power_mean'] = np.mean(power_sequence)
        features['power_std'] = np.std(power_sequence)
        features['power_max'] = np.max(power_sequence)
        features['power_min'] = np.min(power_sequence)
        
        # å˜åŒ–ç‡ç‰¹å¾
        power_diff = np.diff(power_sequence)
        features['diff_mean'] = np.mean(power_diff)
        features['diff_std'] = np.std(power_diff)
        features['max_rise_rate'] = np.max(power_diff)
        features['max_fall_rate'] = np.min(power_diff)
        
        # é¢‘åŸŸç‰¹å¾
        fft = np.fft.fft(power_sequence)
        power_spectrum = np.abs(fft[:len(fft)//2])
        features['dominant_freq'] = np.argmax(power_spectrum)
        features['spectral_centroid'] = np.sum(np.arange(len(power_spectrum)) * power_spectrum) / np.sum(power_spectrum)
        
        # ç»Ÿè®¡ç‰¹å¾
        features['zero_crossing_rate'] = np.sum(np.diff(np.sign(power_sequence - np.mean(power_sequence))) != 0)
        features['energy'] = np.sum(power_sequence ** 2)
        
        return features
```

### 4. è®¾å¤‡ç‰¹å®šæ¨¡å‹

```python
class ApplianceSpecificNILM:
    def __init__(self):
        self.appliance_models = {
            'microwave': MicrowaveDetector(),      # ä¸“é—¨æ£€æµ‹çŸ­æ—¶é«˜åŠŸç‡
            'fridge': CyclicApplianceDetector(),   # ä¸“é—¨æ£€æµ‹å‘¨æœŸæ€§è®¾å¤‡
            'washer_dryer': LongRunningDetector(), # ä¸“é—¨æ£€æµ‹é•¿æ—¶é—´è¿è¡Œè®¾å¤‡
            'dishwasher': LongRunningDetector()
        }
    
    def train_appliance_specific(self, data_module):
        for appliance, model in self.appliance_models.items():
            # ä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºä¸“é—¨çš„è®­ç»ƒæ•°æ®
            appliance_data = self.create_appliance_specific_data(data_module, appliance)
            
            # ä½¿ç”¨è®¾å¤‡ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡
            model.train(appliance_data)
    
    def predict(self, power_sequence):
        predictions = {}
        for appliance, model in self.appliance_models.items():
            predictions[appliance] = model.predict(power_sequence)
        return predictions
```

## ğŸ’¡ æœ€ä½³å®è·µå»ºè®®

### 1. æ¨èçš„å®Œæ•´å·¥ä½œæµç¨‹

```python
# æ­¥éª¤1: åˆ›å»ºæ•°æ®æ¨¡å—ï¼ˆé›†æˆæ‰€æœ‰6ä¸ªæŠ€æœ¯ï¼‰
data_module = RobustNILMDataModule(
    data_path='path/to/data.h5',
    cv_mode=True,
    train_stride=1,
    val_stride=64
)

# æ­¥éª¤2: 5æŠ˜Walk-Forwardäº¤å‰éªŒè¯
for fold in range(5):
    data_module.setup_fold(fold)
    
    # æ­¥éª¤3: è®­ç»ƒè®¾å¤‡ç‰¹å®šæ¨¡å‹
    appliance_models = ApplianceSpecificNILM()
    appliance_models.train_appliance_specific(data_module)
    
    # æ­¥éª¤4: åŠ¨æ€é˜ˆå€¼è°ƒæ•´
    threshold_adjuster = DynamicThresholdAdjuster(TARGET_RATIOS)
    
    # æ­¥éª¤5: å¤šæ¨¡æ€ç‰¹å¾å¢å¼º
    feature_extractor = MultiModalFeatureExtractor()
    
    # è®­ç»ƒå’ŒéªŒè¯...
```

### 2. æ€§èƒ½ç›‘æ§æŒ‡æ ‡

```python
# ç›‘æ§æ‰€æœ‰æŠ€æœ¯çš„æ•ˆæœ
monitoring_metrics = {
    'data_leakage_score': 0.0,      # æ•°æ®æ³„æ¼é£é™©è¯„åˆ†
    'temporal_independence': 0.95,   # æ—¶åºç‹¬ç«‹æ€§
    'label_balance_score': 0.8,      # æ ‡ç­¾å¹³è¡¡æ€§
    'validation_stability': 0.9,     # éªŒè¯ç¨³å®šæ€§
    'generalization_gap': 0.05       # æ³›åŒ–å·®è·
}
```

### 3. æ•…éšœæ’é™¤

**é—®é¢˜**: å¾®æ³¢ç‚‰æ£€æµ‹ç‡ä»ç„¶å¾ˆä½  
**è§£å†³**: ä½¿ç”¨åˆæˆæ•°æ®å¢å¼º + æ›´æ•æ„Ÿé˜ˆå€¼ + å˜åŒ–ç‡ç‰¹å¾

**é—®é¢˜**: éªŒè¯é›†æ€§èƒ½ä¸ç¨³å®š  
**è§£å†³**: å¢åŠ embargoé—´éš” + æ£€æŸ¥éé‡å çª—å£è®¾ç½®

**é—®é¢˜**: è®­ç»ƒæ—¶é—´è¿‡é•¿  
**è§£å†³**: è°ƒæ•´train_stride + ä½¿ç”¨æ›´å°çš„sequence_length

## ğŸ¯ æ€»ç»“

**æ‚¨å¯ä»¥å¹¶ä¸”åº”è¯¥åŒæ—¶ä½¿ç”¨æ‰€æœ‰6ä¸ªé˜²æ³„æ¼æŠ€æœ¯ï¼** å®ƒä»¬æ˜¯ä¸€ä¸ªå®Œæ•´çš„é˜²æŠ¤ä½“ç³»ï¼š

1. **æŠ€æœ¯1-2**: é˜²æ­¢æ—¶åºå’Œé¢„å¤„ç†æ³„æ¼
2. **æŠ€æœ¯3-4**: ä¼˜åŒ–é‡‡æ ·ç­–ç•¥
3. **æŠ€æœ¯5-6**: é˜²æ­¢ç‰¹å¾å’Œæ ‡ç­¾æ³„æ¼

é…åˆ4ä¸ªåç»­ä¼˜åŒ–å»ºè®®ï¼Œæ‚¨å°†æ‹¥æœ‰ä¸šç•Œæœ€å…ˆè¿›çš„NILMæ•°æ®å¤„ç†ç®¡é“ï¼Œç¡®ä¿æ¨¡å‹çš„çœŸå®æ€§èƒ½å’Œéƒ¨ç½²æ•ˆæœï¼