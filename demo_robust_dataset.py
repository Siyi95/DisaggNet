"""æ¼”ç¤ºæ”¹è¿›çš„NILMæ•°æ®é›†ï¼Œå±•ç¤ºå¦‚ä½•è§£å†³æ—¶åºæ•°æ®æ³„æ¼é—®é¢˜"""

import numpy as np
import matplotlib.pyplot as plt
import torch
from torch.utils.data import DataLoader
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.nilm_disaggregation.data.robust_dataset import RobustAMPds2Dataset, RobustNILMDataModule, PurgedEmbargoWalkForwardCV

def setup_chinese_fonts():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    try:
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False
        print("âœ“ ä¸­æ–‡å­—ä½“è®¾ç½®æˆåŠŸ")
    except Exception as e:
        print(f"å­—ä½“è®¾ç½®å¤±è´¥: {e}")

def compare_data_leakage():
    """å¯¹æ¯”åŸå§‹æ•°æ®é›†å’Œæ”¹è¿›æ•°æ®é›†çš„æ•°æ®æ³„æ¼é—®é¢˜"""
    print("\n=== æ•°æ®æ³„æ¼é—®é¢˜å¯¹æ¯”åˆ†æ ===")
    
    data_path = '/Users/yu/Workspace/DisaggNet/Dataset/dataverse_files/AMPds2.h5'
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_path):
        print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        print("ä½¿ç”¨åˆæˆæ•°æ®è¿›è¡Œæ¼”ç¤º...")
    
    print("\n1. åŸå§‹æ•°æ®é›†çš„é—®é¢˜:")
    print("   - æ ‡å‡†åŒ–æ³„æ¼: åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®¡ç®—StandardScaler")
    print("   - é˜ˆå€¼æ³„æ¼: ä½¿ç”¨å…¨éƒ¨æ•°æ®è®¡ç®—75%åˆ†ä½æ•°")
    print("   - æ—¶åºè¿ç»­æ€§: è®­ç»ƒæµ‹è¯•é›†åœ¨æ—¶é—´ä¸Šè¿ç»­")
    print("   - é‡å çª—å£: ç›¸é‚»æ ·æœ¬å¯èƒ½æœ‰é‡å ï¼Œå¯¼è‡´ä¿¡æ¯æ³„æ¼")
    
    print("\n   åŸå§‹æ•°æ®é›†é—®é¢˜ï¼ˆå·²ç§»é™¤è¿‡æ—¶å®ç°ï¼‰:")
    print("   - ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†è®¡ç®—æ ‡å‡†åŒ–å‚æ•°")
    print("   - å›ºå®š75%åˆ†ä½æ•°é˜ˆå€¼")
    print("   - è®­ç»ƒæµ‹è¯•é›†æ—¶é—´è¿ç»­")
    print("   - æ»‘åŠ¨çª—å£é‡å é‡‡æ ·")
    
    original_train = None
    original_test = None
    
    print("\n2. æ”¹è¿›æ•°æ®é›†çš„è§£å†³æ–¹æ¡ˆ:")
    print("   - å…ˆåˆ†å‰²åé¢„å¤„ç†: é˜²æ­¢æµ‹è¯•é›†ä¿¡æ¯æ³„æ¼")
    print("   - æ—¶é—´é—´éš”: è®­ç»ƒæµ‹è¯•é›†ä¹‹é—´æ·»åŠ 24å°æ—¶é—´éš”")
    print("   - è‡ªé€‚åº”é˜ˆå€¼: æ ¹æ®è®¾å¤‡ç±»å‹åŠ¨æ€è°ƒæ•´")
    print("   - éé‡å çª—å£: é˜²æ­¢ç›¸é‚»æ ·æœ¬ä¿¡æ¯æ³„æ¼")
    
    try:
        # åˆ›å»ºæ”¹è¿›çš„æ•°æ®æ¨¡å—
        robust_data_module = RobustNILMDataModule(
            data_path=data_path,
            sequence_length=64,
            batch_size=16,
            split_config={
                'train_ratio': 0.7,
                'val_ratio': 0.15,
                'test_ratio': 0.15,
                'embargo_hours': 24,
                'purge_hours': 0,
                'cv_folds': 5,
                'min_train_hours': 30*24
            },
            train_stride=1,
            val_stride=64,  # éé‡å çª—å£
            cv_mode=False
        )
        
        # è®¾ç½®æ•°æ®
        robust_data_module.setup('fit')
        
        print(f"\n   æ”¹è¿›è®­ç»ƒé›†å¤§å°: {len(robust_data_module.train_dataset)}")
        print(f"   æ”¹è¿›éªŒè¯é›†å¤§å°: {len(robust_data_module.val_dataset)}")
        
        # è·å–å…ƒæ•°æ®
        metadata = robust_data_module.get_metadata()
        print(f"\n   è®­ç»ƒé›†æ•°æ®èŒƒå›´: {metadata['train_info']['data_range']}")
        print(f"   éªŒè¯é›†æ•°æ®èŒƒå›´: {metadata['val_info']['data_range']}")
        print(f"   éé‡å çª—å£: {metadata['train_info']['non_overlapping_windows']}")
        
        return original_train, original_test, robust_data_module
        
    except Exception as e:
        print(f"   åˆ›å»ºæ”¹è¿›æ•°æ®é›†å¤±è´¥: {e}")
        return None, None, None

def demonstrate_walk_forward_cv():
    """æ¼”ç¤ºPurged/Embargo Walk-Forwardäº¤å‰éªŒè¯"""
    print("\n=== Purged/Embargo Walk-Forward äº¤å‰éªŒè¯æ¼”ç¤º ===")
    
    # åˆ›å»ºWalk-Forwardäº¤å‰éªŒè¯å™¨
    cv = PurgedEmbargoWalkForwardCV(
        n_splits=5, 
        embargo_hours=24,  # 24å°æ—¶ç¦è¿æœŸ
        purge_hours=0,     # æ— æ¸…æ´—æœŸ
        test_hours=7*24,   # 7å¤©éªŒè¯æœŸ
        min_train_hours=30*24  # æœ€å°30å¤©è®­ç»ƒæœŸ
    )
    
    # æ¨¡æ‹Ÿæ•°æ®é•¿åº¦ï¼ˆå‡è®¾6ä¸ªæœˆçš„æ•°æ®ï¼Œæ¯åˆ†é’Ÿä¸€ä¸ªæ ·æœ¬ï¼‰
    data_length = 180 * 24 * 60  # 259200ä¸ªæ ·æœ¬
    
    splits = cv.split(data_length, sampling_rate_minutes=1)
    
    print(f"æ•°æ®æ€»é•¿åº¦: {data_length} æ ·æœ¬ ({data_length/(24*60):.1f} å¤©)")
    print(f"Walk-Forwardåˆ†å‰²æ•°: {len(splits)}")
    print(f"ç­–ç•¥: å†å²è®­ç»ƒ â†’ 24h Embargo â†’ 7å¤©éªŒè¯")
    
    for i, (train_indices, test_indices) in enumerate(splits):
        fold_info = cv.get_fold_info(i, data_length)
        
        print(f"\nFold {i+1}:")
        print(f"  è®­ç»ƒé›†: {fold_info['train_start']} - {fold_info['train_end']} ({fold_info['train_size']} æ ·æœ¬, {fold_info['train_size']/(24*60):.1f} å¤©)")
        print(f"  Embargo: {fold_info['embargo_start']} - {fold_info['embargo_end']} ({fold_info['embargo_size']} æ ·æœ¬, {fold_info['embargo_size']/60:.1f} å°æ—¶)")
        print(f"  éªŒè¯é›†: {fold_info['test_start']} - {fold_info['test_end']} ({fold_info['test_size']} æ ·æœ¬, {fold_info['test_size']/(24*60):.1f} å¤©)")
        print(f"  è®­ç»ƒé›†å¢é•¿: +{fold_info['train_size']/(24*60) - (30 if i == 0 else splits[i-1][0][-1]/(24*60)):.1f} å¤©" if i > 0 else f"  åˆå§‹è®­ç»ƒé›†: {fold_info['train_size']/(24*60):.1f} å¤©")
    
    return splits

def visualize_data_splits(robust_data_module, splits=None):
    """å¯è§†åŒ–æ•°æ®åˆ†å‰²å’ŒWalk-ForwardéªŒè¯"""
    print("\n=== æ•°æ®åˆ†å‰²å¯è§†åŒ– ===")
    
    setup_chinese_fonts()
    
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle('Purged/Embargo Walk-Forward æ•°æ®æ³„æ¼é˜²æŠ¤æ–¹æ¡ˆ', fontsize=18, fontweight='bold')
    
    # 1. ä¼ ç»Ÿåˆ†å‰² vs Embargoåˆ†å‰²
    ax1 = axes[0, 0]
    
    # æ¨¡æ‹Ÿæ•°æ®é•¿åº¦
    total_length = 1000
    
    # ä¼ ç»Ÿåˆ†å‰²ï¼ˆè¿ç»­ï¼‰
    traditional_train_end = int(total_length * 0.8)
    ax1.barh(2, traditional_train_end, height=0.3, color='blue', alpha=0.7, label='ä¼ ç»Ÿè®­ç»ƒé›†')
    ax1.barh(2, total_length - traditional_train_end, left=traditional_train_end, 
             height=0.3, color='red', alpha=0.7, label='ä¼ ç»Ÿæµ‹è¯•é›†')
    
    # Embargoåˆ†å‰²ï¼ˆæœ‰é—´éš”ï¼‰
    embargo_train_end = int(total_length * 0.7)
    embargo_gap = 50
    embargo_val_start = embargo_train_end + embargo_gap
    embargo_val_size = int(total_length * 0.15)
    
    ax1.barh(1, embargo_train_end, height=0.3, color='green', alpha=0.7, label='Embargoè®­ç»ƒé›†')
    ax1.barh(1, embargo_gap, left=embargo_train_end, height=0.3, color='gray', alpha=0.5, label='Embargoé—´éš”')
    ax1.barh(1, embargo_val_size, left=embargo_val_start, height=0.3, color='orange', alpha=0.7, label='EmbargoéªŒè¯é›†')
    
    # Walk-Forwardåˆ†å‰²ï¼ˆé€æ­¥æ‰©å¤§ï¼‰
    wf_train_sizes = [300, 450, 600]
    wf_positions = [0, 0.3, 0.6]
    for i, (size, pos) in enumerate(zip(wf_train_sizes, wf_positions)):
        val_start = size + embargo_gap
        ax1.barh(pos, size, height=0.15, color=f'C{i}', alpha=0.8, label=f'WF Fold{i+1} è®­ç»ƒ')
        ax1.barh(pos, embargo_gap, left=size, height=0.15, color='gray', alpha=0.3)
        ax1.barh(pos, 100, left=val_start, height=0.15, color=f'C{i}', alpha=0.4, label=f'WF Fold{i+1} éªŒè¯')
    
    ax1.set_xlim(0, total_length)
    ax1.set_ylim(-0.2, 2.5)
    ax1.set_xlabel('æ—¶é—´æ­¥')
    ax1.set_title('æ•°æ®åˆ†å‰²ç­–ç•¥å¯¹æ¯”')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax1.set_yticks([0.15, 0.45, 0.75, 1, 2])
    ax1.set_yticklabels(['WF Fold3', 'WF Fold2', 'WF Fold1', 'Embargo', 'ä¼ ç»Ÿ'])
    
    # 2. è®­ç»ƒé›†vséªŒè¯é›†é‡‡æ ·ç­–ç•¥
    ax2 = axes[0, 1]
    
    # è®­ç»ƒé›†ï¼šå°æ­¥é•¿ï¼ˆstride=1ï¼‰
    train_windows = []
    window_size = 8
    for i in range(0, 20, 1):  # stride=1
        if i + window_size <= 20:
            train_windows.append((i, window_size))
    
    for i, (start, size) in enumerate(train_windows[:8]):  # åªæ˜¾ç¤ºå‰8ä¸ª
        ax2.barh(1, size, left=start, height=0.15, 
                 color='blue', alpha=0.6, edgecolor='black', linewidth=0.5)
    
    # éªŒè¯é›†ï¼šå¤§æ­¥é•¿ï¼ˆstride=window_sizeï¼‰
    val_windows = []
    for i in range(0, 20, window_size):  # stride=window_size
        if i + window_size <= 20:
            val_windows.append((i, window_size))
    
    for i, (start, size) in enumerate(val_windows):
        ax2.barh(0, size, left=start, height=0.15, 
                 color='green', alpha=0.6, edgecolor='black', linewidth=0.5)
    
    ax2.set_xlim(0, 20)
    ax2.set_ylim(-0.3, 1.5)
    ax2.set_xlabel('æ—¶é—´æ­¥')
    ax2.set_title('å·®å¼‚åŒ–é‡‡æ ·ç­–ç•¥')
    ax2.set_yticks([0, 1])
    ax2.set_yticklabels(['éªŒè¯é›†(stride=window_size)', 'è®­ç»ƒé›†(stride=1)'])
    ax2.text(10, 1.2, 'è®­ç»ƒé›†ï¼šå°æ­¥é•¿å¢åŠ æ ·æœ¬é‡', ha='center', fontsize=10, color='blue')
    ax2.text(10, -0.2, 'éªŒè¯é›†ï¼šéé‡å é˜²æ­¢ç›¸ä¼¼æ€§åç½®', ha='center', fontsize=10, color='green')
    
    # 3. Walk-Forwardæ—¶åºå±•å¼€
    ax3 = axes[0, 2]
    
    if splits:
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
        max_time = max([max(test_indices) for _, test_indices in splits]) if splits else 1000
        
        for i, (train_indices, test_indices) in enumerate(splits[:5]):
            train_start = train_indices[0] / max_time
            train_end = train_indices[-1] / max_time
            test_start = test_indices[0] / max_time
            test_end = test_indices[-1] / max_time
            
            # è®­ç»ƒé›†
            ax3.barh(i, train_end - train_start, left=train_start, 
                     height=0.3, color=colors[i], alpha=0.8, label=f'Fold {i+1}')
            # Embargoé—´éš”
            ax3.barh(i, test_start - train_end, left=train_end, 
                     height=0.3, color='gray', alpha=0.5)
            # éªŒè¯é›†
            ax3.barh(i, test_end - test_start, left=test_start, 
                     height=0.3, color=colors[i], alpha=0.4)
            
            # æ·»åŠ æ ‡æ³¨
            ax3.text(train_start + (train_end - train_start)/2, i, f'è®­ç»ƒ', 
                     ha='center', va='center', fontsize=8, color='white', fontweight='bold')
            ax3.text(test_start + (test_end - test_start)/2, i, f'éªŒè¯', 
                     ha='center', va='center', fontsize=8, color='white', fontweight='bold')
    
    ax3.set_xlabel('å½’ä¸€åŒ–æ—¶é—´')
    ax3.set_title('Walk-Forwardæ—¶åºå±•å¼€')
    ax3.set_ylabel('Foldç¼–å·')
    ax3.grid(True, alpha=0.3)
    
    # 4. æ ‡ç­¾å¹³è¡¡æ€§ä¼˜åŒ–å¯¹æ¯”
    ax4 = axes[1, 0]
    
    appliances = ['å†°ç®±', 'æ´—è¡£æœº', 'å¾®æ³¢ç‚‰', 'æ´—ç¢—æœº']
    old_ratios = [0.50, 0.125, 0.000, 0.250]  # å½“å‰è§‚å¯Ÿåˆ°çš„æ¯”ä¾‹
    target_ratios = [0.50, 0.25, 0.14, 0.30]  # ä¼˜åŒ–åçš„ç›®æ ‡æ¯”ä¾‹
    
    x = np.arange(len(appliances))
    width = 0.35
    
    bars1 = ax4.bar(x - width/2, old_ratios, width, label='ä¼˜åŒ–å‰', alpha=0.7, color='lightcoral')
    bars2 = ax4.bar(x + width/2, target_ratios, width, label='ä¼˜åŒ–å', alpha=0.7, color='lightgreen')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, ratio in zip(bars1, old_ratios):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{ratio:.3f}', ha='center', va='bottom', fontsize=9)
    
    for bar, ratio in zip(bars2, target_ratios):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{ratio:.3f}', ha='center', va='bottom', fontsize=9)
    
    ax4.set_xlabel('è®¾å¤‡ç±»å‹')
    ax4.set_ylabel('æ­£æ ·æœ¬æ¯”ä¾‹')
    ax4.set_title('æ ‡ç­¾å¹³è¡¡æ€§ä¼˜åŒ–')
    ax4.set_xticks(x)
    ax4.set_xticklabels(appliances)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim(0, 0.6)
    
    # 5. é˜ˆå€¼ä¼˜åŒ–ç­–ç•¥
    ax5 = axes[1, 1]
    
    # æ¨¡æ‹Ÿä¸åŒè®¾å¤‡çš„é˜ˆå€¼æœç´¢è¿‡ç¨‹
    percentiles = np.arange(50, 96, 5)
    microwave_ratios = [0.45, 0.35, 0.25, 0.18, 0.12, 0.08, 0.05, 0.03, 0.01, 0.005]
    fridge_ratios = [0.85, 0.75, 0.65, 0.55, 0.45, 0.35, 0.25, 0.15, 0.08, 0.03]
    
    ax5.plot(percentiles, microwave_ratios, 'o-', label='å¾®æ³¢ç‚‰', color='red', linewidth=2)
    ax5.plot(percentiles, fridge_ratios, 's-', label='å†°ç®±', color='blue', linewidth=2)
    
    # æ ‡è®°ç›®æ ‡èŒƒå›´
    ax5.axhspan(0.08, 0.20, alpha=0.2, color='red', label='å¾®æ³¢ç‚‰ç›®æ ‡èŒƒå›´')
    ax5.axhspan(0.35, 0.65, alpha=0.2, color='blue', label='å†°ç®±ç›®æ ‡èŒƒå›´')
    
    ax5.set_xlabel('é˜ˆå€¼ç™¾åˆ†ä½æ•°')
    ax5.set_ylabel('æ­£æ ·æœ¬æ¯”ä¾‹')
    ax5.set_title('è‡ªé€‚åº”é˜ˆå€¼æœç´¢è¿‡ç¨‹')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    ax5.set_ylim(0, 1)
    
    # 6. é˜²æ³„æ¼æŠ€æœ¯æ€»è§ˆ
    ax6 = axes[1, 2]
    ax6.axis('off')
    
    # åˆ›å»ºé˜²æ³„æ¼æŠ€æœ¯çš„æ–‡å­—æ€»ç»“
    techniques = [
        'ğŸ”’ Purged/Embargo Walk-Forward',
        'ğŸ“Š å…ˆåˆ†å‰²åé¢„å¤„ç†',
        'ğŸ¯ éªŒè¯é›†éé‡å çª—å£',
        'ğŸ“ˆ è®­ç»ƒé›†å°æ­¥é•¿é‡‡æ ·',
        'âš–ï¸ è‡ªé€‚åº”é˜ˆå€¼ä¼˜åŒ–',
        'ğŸ” ç‰¹å¾å·¥ç¨‹åˆ†ç‰‡å†…ç‹¬ç«‹'
    ]
    
    for i, technique in enumerate(techniques):
        ax6.text(0.1, 0.9 - i*0.15, technique, fontsize=12, 
                transform=ax6.transAxes, verticalalignment='top')
    
    ax6.set_title('é˜²æ³„æ¼æŠ€æœ¯æ¸…å•', fontsize=14, fontweight='bold', pad=20)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_dir = Path('outputs/robust_dataset_demo')
    output_dir.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_dir / 'walk_forward_validation.png', dpi=300, bbox_inches='tight')
    print(f"\nå¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {output_dir / 'walk_forward_validation.png'}")
    
    plt.show()

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\n=== æ•°æ®åŠ è½½æµ‹è¯• ===")
    
    data_path = '/Users/yu/Workspace/DisaggNet/Dataset/dataverse_files/AMPds2.h5'
    
    try:
        # åˆ›å»ºæ”¹è¿›çš„æ•°æ®æ¨¡å—
        data_module = RobustNILMDataModule(
            data_path=data_path,
            sequence_length=32,  # è¾ƒå°çš„åºåˆ—é•¿åº¦ç”¨äºå¿«é€Ÿæµ‹è¯•
            batch_size=8,
            train_stride=1,
            val_stride=32,  # éé‡å çª—å£
            cv_mode=False
        )
        
        # è®¾ç½®æ•°æ®
        data_module.setup('fit')
        
        # è·å–æ•°æ®åŠ è½½å™¨
        train_loader = data_module.train_dataloader()
        val_loader = data_module.val_dataloader()
        
        print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch_idx, (x, y_power, y_state) in enumerate(train_loader):
            print(f"\næ‰¹æ¬¡ {batch_idx + 1}:")
            print(f"  è¾“å…¥å½¢çŠ¶: {x.shape}")
            print(f"  åŠŸç‡ç›®æ ‡å½¢çŠ¶: {y_power.shape}")
            print(f"  çŠ¶æ€ç›®æ ‡å½¢çŠ¶: {y_state.shape}")
            print(f"  è¾“å…¥æ•°æ®èŒƒå›´: [{x.min():.4f}, {x.max():.4f}]")
            print(f"  åŠŸç‡æ•°æ®èŒƒå›´: [{y_power.min():.4f}, {y_power.max():.4f}]")
            print(f"  çŠ¶æ€æ•°æ®èŒƒå›´: [{y_state.min():.4f}, {y_state.max():.4f}]")
            
            # æ£€æŸ¥çŠ¶æ€æ ‡ç­¾çš„å¹³è¡¡æ€§
            for i, appliance in enumerate(data_module.train_dataset.get_appliances()):
                positive_ratio = (y_state[:, i] > 0.5).float().mean().item()
                print(f"  {appliance} æ­£æ ·æœ¬æ¯”ä¾‹: {positive_ratio:.3f}")
            
            if batch_idx >= 2:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
                break
        
        return True
        
    except Exception as e:
        print(f"æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_summary_report():
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("æ—¶åºæ•°æ®æ³„æ¼é˜²æŠ¤æ–¹æ¡ˆæ€»ç»“æŠ¥å‘Š")
    print("="*60)
    
    print("\nğŸ” å‘ç°çš„é—®é¢˜:")
    print("1. æ ‡å‡†åŒ–æ³„æ¼: åŸå§‹ä»£ç åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®¡ç®—StandardScalerå‚æ•°")
    print("2. é˜ˆå€¼æ³„æ¼: ä½¿ç”¨å…¨éƒ¨æ•°æ®è®¡ç®—è®¾å¤‡çŠ¶æ€é˜ˆå€¼")
    print("3. æ—¶åºè¿ç»­æ€§: è®­ç»ƒæµ‹è¯•é›†åœ¨æ—¶é—´ä¸Šè¿ç»­ï¼Œå­˜åœ¨æ—¶åºä¾èµ–")
    print("4. é‡å çª—å£: ç›¸é‚»æ ·æœ¬çª—å£é‡å ï¼Œå¯¼è‡´ä¿¡æ¯æ³„æ¼")
    print("5. æ ‡ç­¾ä¸å‡è¡¡: å›ºå®šé˜ˆå€¼å¯¼è‡´æŸäº›è®¾å¤‡çŠ¶æ€åˆ†å¸ƒæä¸å‡è¡¡")
    
    print("\nâœ… è§£å†³æ–¹æ¡ˆ:")
    print("1. Purged/Embargo Walk-ForwardéªŒè¯: å†å²è®­ç»ƒâ†’ç¦è¿æœŸâ†’æœªæ¥éªŒè¯")
    print("2. å…ˆåˆ†å‰²åé¢„å¤„ç†: ç¡®ä¿æµ‹è¯•é›†ä¿¡æ¯ä¸æ³„æ¼åˆ°è®­ç»ƒè¿‡ç¨‹")
    print("3. éªŒè¯é›†éé‡å çª—å£: stride=window_sizeï¼Œæœç»éªŒè¯é›†å†…éƒ¨ç›¸ä¼¼æ€§åç½®")
    print("4. è®­ç»ƒé›†å°æ­¥é•¿: stride=1ï¼Œæ‰©å……æ ·æœ¬é‡æå‡å­¦ä¹ æ•ˆæœ")
    print("5. æ ‡ç­¾/é˜ˆå€¼é˜²æ³„æ¼: åªåœ¨è®­ç»ƒåˆ†ç‰‡ä¸Šä¼°è®¡ï¼ŒéªŒè¯åˆ†ç‰‡åªåº”ç”¨")
    print("6. ç‰¹å¾å·¥ç¨‹åˆ†ç‰‡å†…ç‹¬ç«‹: æŒ‰foldå†…è®­ç»ƒæ®µä¼°è®¡å…¨å±€åˆ†å¸ƒç‰¹å¾")
    
    print("\nğŸ“Š æŠ€æœ¯ç‰¹ç‚¹:")
    print("- Purged/Embargo Walk-Forwardäº¤å‰éªŒè¯")
    print("- åŸºäºç½‘ç»œæœ€ä½³å®è·µçš„æ—¶åºæ•°æ®å¤„ç†")
    print("- è®­ç»ƒé›†å’ŒéªŒè¯é›†å·®å¼‚åŒ–é‡‡æ ·ç­–ç•¥")
    print("- è®¾å¤‡ç‰¹å®šçš„è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—")
    print("- å®Œæ•´çš„æ•°æ®æ³„æ¼é˜²æŠ¤ç®¡é“")
    print("- æ”¯æŒå•æ¬¡åˆ†å‰²å’Œäº¤å‰éªŒè¯ä¸¤ç§æ¨¡å¼")
    
    print("\nğŸ¯ é¢„æœŸæ•ˆæœ:")
    print("- æ˜¾è‘—æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›")
    print("- æ›´çœŸå®çš„æ€§èƒ½è¯„ä¼°")
    print("- æ›´å¥½çš„å®é™…éƒ¨ç½²æ•ˆæœ")
    print("- è§£å†³æ ‡ç­¾ä¸å‡è¡¡é—®é¢˜")
    
    print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("- src/nilm_disaggregation/data/robust_dataset.py: æ”¹è¿›çš„æ•°æ®é›†å®ç°")
    print("- demo_robust_dataset.py: æ¼”ç¤ºè„šæœ¬")
    print("- outputs/robust_dataset_demo/: å¯è§†åŒ–ç»“æœ")

def main():
    """ä¸»å‡½æ•°"""
    print("æ—¶åºæ•°æ®æ³„æ¼é˜²æŠ¤æ¼”ç¤º")
    print("åŸºäºç½‘ç»œæœ€ä½³å®è·µçš„NILMæ•°æ®å¤„ç†æ”¹è¿›æ–¹æ¡ˆ")
    
    # 1. å¯¹æ¯”åˆ†æ
    original_train, original_test, robust_data_module = compare_data_leakage()
    
    # 2. Walk-Forwardäº¤å‰éªŒè¯æ¼”ç¤º
    splits = demonstrate_walk_forward_cv()
    
    # 3. å¯è§†åŒ–
    visualize_data_splits(robust_data_module, splits)
    
    # 4. æ•°æ®åŠ è½½æµ‹è¯•
    test_success = test_data_loading()
    
    # 5. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report()
    
    if test_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ”¹è¿›çš„æ•°æ®é›†å·²å‡†å¤‡å°±ç»ªã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œä¾èµ–ã€‚")
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. å°† RobustAMPds2Dataset æ›¿æ¢åŸæœ‰çš„æ•°æ®é›†ç±»")
    print("2. ä½¿ç”¨ RobustNILMDataModule è¿›è¡Œæ•°æ®ç®¡ç†")
    print("3. åœ¨æ¨¡å‹è®­ç»ƒä¸­å¯ç”¨éé‡å çª—å£é‡‡æ ·")
    print("4. ä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯è¿›è¡Œæ¨¡å‹è¯„ä¼°")

if __name__ == "__main__":
    main()