#!/usr/bin/env python3
"""
åœ¨çº¿TCNæ£€æµ‹è„šæœ¬
ä½¿ç”¨è½»é‡çº§å› æœTCNæ¨¡å‹è¿›è¡Œå®æ—¶è®¾å¤‡å¯åœæ£€æµ‹
"""

import os
import sys
import argparse
import yaml
import time
import json
import threading
from queue import Queue, Empty
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Callable
import numpy as np
import torch
import torch.nn.functional as F
from collections import deque
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.tcn_online import OnlineEventDetector, OnlineBuffer
from src.features import FeatureExtractor

class RealTimeDataSimulator:
    """å®æ—¶æ•°æ®æ¨¡æ‹Ÿå™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    
    def __init__(self, 
                 data_path: str,
                 feature_extractor: FeatureExtractor,
                 start_idx: int = 0,
                 speed_factor: float = 1.0):
        """
        åˆå§‹åŒ–æ•°æ®æ¨¡æ‹Ÿå™¨
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            feature_extractor: ç‰¹å¾æå–å™¨
            start_idx: å¼€å§‹ç´¢å¼•
            speed_factor: é€Ÿåº¦å› å­ï¼ˆ>1è¡¨ç¤ºåŠ é€Ÿï¼‰
        """
        self.data_path = data_path
        self.feature_extractor = feature_extractor
        self.start_idx = start_idx
        self.speed_factor = speed_factor
        
        # åŠ è½½æ•°æ®
        self._load_data()
        
        # çŠ¶æ€
        self.current_idx = start_idx
        self.is_running = False
        
    def _load_data(self):
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        import h5py
        
        print(f"åŠ è½½æ•°æ®: {self.data_path}")
        with h5py.File(self.data_path, 'r') as f:
            # åŠ è½½åŸå§‹æ•°æ®
            self.timestamps = f['timestamps'][:]
            self.power_data = f['power'][:]
            
            # å¦‚æœæœ‰å…¶ä»–é€šé“æ•°æ®
            self.other_channels = {}
            for key in f.keys():
                if key not in ['timestamps', 'power'] and 'power' not in key.lower():
                    self.other_channels[key] = f[key][:]
        
        print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œé•¿åº¦: {len(self.timestamps)}")
    
    def get_next_sample(self) -> Optional[Dict[str, Any]]:
        """
        è·å–ä¸‹ä¸€ä¸ªæ•°æ®æ ·æœ¬
        
        Returns:
            æ•°æ®æ ·æœ¬å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰æ›´å¤šæ•°æ®åˆ™è¿”å›None
        """
        if self.current_idx >= len(self.timestamps):
            return None
        
        # è·å–å½“å‰æ—¶é—´ç‚¹çš„æ•°æ®
        timestamp = self.timestamps[self.current_idx]
        power = self.power_data[self.current_idx]
        
        # æ„å»ºå¤šé€šé“è¾“å…¥
        channels = {'P_total': power}
        for key, data in self.other_channels.items():
            if self.current_idx < len(data):
                channels[key] = data[self.current_idx]
        
        # æå–ç‰¹å¾
        features = self.feature_extractor.extract_single_sample(
            channels, timestamp
        )
        
        sample = {
            'timestamp': timestamp,
            'features': features,
            'raw_power': power
        }
        
        self.current_idx += 1
        return sample
    
    def start_streaming(self, callback: Callable[[Dict[str, Any]], None]):
        """
        å¼€å§‹æµå¼ä¼ è¾“æ•°æ®
        
        Args:
            callback: æ•°æ®å›è°ƒå‡½æ•°
        """
        self.is_running = True
        
        def stream_worker():
            while self.is_running:
                sample = self.get_next_sample()
                if sample is None:
                    print("æ•°æ®æµç»“æŸ")
                    break
                
                # è°ƒç”¨å›è°ƒå‡½æ•°
                callback(sample)
                
                # æ§åˆ¶é€Ÿåº¦
                time.sleep(60.0 / self.speed_factor)  # æ¯åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œ
        self.stream_thread = threading.Thread(target=stream_worker)
        self.stream_thread.start()
    
    def stop_streaming(self):
        """åœæ­¢æµå¼ä¼ è¾“"""
        self.is_running = False
        if hasattr(self, 'stream_thread'):
            self.stream_thread.join()

class OnlineDetectionSystem:
    """åœ¨çº¿æ£€æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, 
                 model_path: str,
                 config_path: str,
                 device: str = 'auto',
                 buffer_size: int = 120,
                 detection_threshold: float = 0.5,
                 min_duration: int = 3,
                 event_callback: Optional[Callable] = None):
        """
        åˆå§‹åŒ–åœ¨çº¿æ£€æµ‹ç³»ç»Ÿ
        
        Args:
            model_path: TCNæ¨¡å‹è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
            buffer_size: ç¼“å†²åŒºå¤§å°ï¼ˆåˆ†é’Ÿï¼‰
            detection_threshold: æ£€æµ‹é˜ˆå€¼
            min_duration: æœ€å°æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            event_callback: äº‹ä»¶å›è°ƒå‡½æ•°
        """
        self.device = self._setup_device(device)
        self.buffer_size = buffer_size
        self.detection_threshold = detection_threshold
        self.min_duration = min_duration
        self.event_callback = event_callback
        
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        feature_config = self.config.get('features', {})
        self.feature_extractor = FeatureExtractor(**feature_config)
        
        # åŠ è½½æ¨¡å‹
        print(f"åŠ è½½TCNæ¨¡å‹: {model_path}")
        self.detector = OnlineEventDetector.load_from_checkpoint(
            model_path, map_location=self.device
        )
        self.detector.eval()
        self.detector.to(self.device)
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        self.input_dim = self.detector.hparams.input_dim
        self.num_devices = self.detector.hparams.num_devices
        self.device_names = getattr(self.detector, 'device_names', 
                                   [f'Device_{i}' for i in range(self.num_devices)])
        
        # åˆå§‹åŒ–ç¼“å†²åŒº
        self.buffer = OnlineBuffer(
            buffer_size=buffer_size,
            feature_dim=self.input_dim
        )
        
        # çŠ¶æ€è·Ÿè¸ª
        self.current_states = np.zeros(self.num_devices, dtype=bool)
        self.state_durations = np.zeros(self.num_devices, dtype=int)
        self.last_change_times = [None] * self.num_devices
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_samples': 0,
            'total_events': 0,
            'device_events': {name: 0 for name in self.device_names},
            'start_time': datetime.now()
        }
        
        # æ—¥å¿—è®¾ç½®
        self._setup_logging()
        
        print(f"åœ¨çº¿æ£€æµ‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"æ”¯æŒè®¾å¤‡: {self.device_names}")
        print(f"ç¼“å†²åŒºå¤§å°: {buffer_size} åˆ†é’Ÿ")
    
    def _setup_device(self, device: str) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device == 'auto':
            if torch.cuda.is_available():
                device = 'cuda'
            else:
                device = 'cpu'
        return torch.device(device)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('online_detection.log')
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def process_sample(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ•°æ®æ ·æœ¬
        
        Args:
            sample: æ•°æ®æ ·æœ¬
        Returns:
            æ£€æµ‹ç»“æœ
        """
        timestamp = sample['timestamp']
        features = sample['features']
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.buffer.add_sample(features, timestamp)
        self.stats['total_samples'] += 1
        
        # æ£€æŸ¥ç¼“å†²åŒºæ˜¯å¦å‡†å¤‡å¥½
        if not self.buffer.is_ready():
            return {
                'timestamp': timestamp,
                'ready': False,
                'message': f'ç¼“å†²åŒºå¡«å……ä¸­ ({self.buffer.current_size}/{self.buffer_size})'
            }
        
        # è·å–ç¼“å†²åŒºæ•°æ®
        buffer_data = self.buffer.get_buffer()  # [buffer_size, feature_dim]
        
        # è½¬æ¢ä¸ºtensorå¹¶æ·»åŠ batchç»´åº¦
        x = torch.from_numpy(buffer_data).float().unsqueeze(0).to(self.device)  # [1, seq_len, feature_dim]
        
        # åœ¨çº¿é¢„æµ‹
        with torch.no_grad():
            predictions = self.detector.predict_online(x)
        
        # æå–æœ€æ–°æ—¶åˆ»çš„é¢„æµ‹
        latest_probs = predictions['state_prob'][0, -1, :].cpu().numpy()  # [num_devices]
        latest_states = (latest_probs > self.detection_threshold).astype(bool)
        
        # æ£€æµ‹çŠ¶æ€å˜åŒ–
        events = self._detect_state_changes(latest_states, timestamp)
        
        # æ›´æ–°çŠ¶æ€
        self._update_states(latest_states, timestamp)
        
        result = {
            'timestamp': timestamp,
            'ready': True,
            'probabilities': latest_probs.tolist(),
            'states': latest_states.tolist(),
            'events': events,
            'current_states': self.current_states.tolist(),
            'state_durations': self.state_durations.tolist()
        }
        
        # è§¦å‘äº‹ä»¶å›è°ƒ
        if events and self.event_callback:
            self.event_callback(result)
        
        return result
    
    def _detect_state_changes(self, new_states: np.ndarray, timestamp: float) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹çŠ¶æ€å˜åŒ–äº‹ä»¶
        
        Args:
            new_states: æ–°çš„çŠ¶æ€æ•°ç»„
            timestamp: æ—¶é—´æˆ³
        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        events = []
        
        for i, (old_state, new_state) in enumerate(zip(self.current_states, new_states)):
            if old_state != new_state:
                # æ£€æŸ¥æœ€å°æŒç»­æ—¶é—´
                if self.state_durations[i] >= self.min_duration:
                    event = {
                        'device_id': i,
                        'device_name': self.device_names[i],
                        'event_type': 'turn_on' if new_state else 'turn_off',
                        'timestamp': timestamp,
                        'datetime': datetime.fromtimestamp(timestamp).isoformat(),
                        'duration': self.state_durations[i],
                        'probability': float(new_states[i])
                    }
                    events.append(event)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats['total_events'] += 1
                    self.stats['device_events'][self.device_names[i]] += 1
                    
                    # è®°å½•æ—¥å¿—
                    self.logger.info(
                        f"è®¾å¤‡ {self.device_names[i]} {event['event_type']} "
                        f"(æŒç»­ {self.state_durations[i]} åˆ†é’Ÿ)"
                    )
        
        return events
    
    def _update_states(self, new_states: np.ndarray, timestamp: float):
        """
        æ›´æ–°è®¾å¤‡çŠ¶æ€
        
        Args:
            new_states: æ–°çš„çŠ¶æ€æ•°ç»„
            timestamp: æ—¶é—´æˆ³
        """
        for i, (old_state, new_state) in enumerate(zip(self.current_states, new_states)):
            if old_state == new_state:
                # çŠ¶æ€æœªå˜åŒ–ï¼Œå¢åŠ æŒç»­æ—¶é—´
                self.state_durations[i] += 1
            else:
                # çŠ¶æ€å˜åŒ–ï¼Œé‡ç½®æŒç»­æ—¶é—´
                self.state_durations[i] = 1
                self.last_change_times[i] = timestamp
        
        # æ›´æ–°å½“å‰çŠ¶æ€
        self.current_states = new_states.copy()
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        current_time = datetime.now()
        runtime = current_time - self.stats['start_time']
        
        stats = self.stats.copy()
        stats.update({
            'runtime_seconds': runtime.total_seconds(),
            'runtime_str': str(runtime),
            'samples_per_minute': self.stats['total_samples'] / max(runtime.total_seconds() / 60, 1),
            'current_states': {
                self.device_names[i]: bool(state) 
                for i, state in enumerate(self.current_states)
            },
            'state_durations': {
                self.device_names[i]: int(duration) 
                for i, duration in enumerate(self.state_durations)
            }
        })
        
        return stats
    
    def save_statistics(self, output_path: str):
        """
        ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        stats = self.get_statistics()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_path}")

def event_handler(result: Dict[str, Any]):
    """äº‹ä»¶å¤„ç†å‡½æ•°ç¤ºä¾‹"""
    events = result.get('events', [])
    
    for event in events:
        print(f"\nğŸ”” è®¾å¤‡äº‹ä»¶æ£€æµ‹:")
        print(f"   è®¾å¤‡: {event['device_name']}")
        print(f"   äº‹ä»¶: {event['event_type']}")
        print(f"   æ—¶é—´: {event['datetime']}")
        print(f"   æŒç»­: {event['duration']} åˆ†é’Ÿ")
        print(f"   æ¦‚ç‡: {event['probability']:.3f}")

def main():
    parser = argparse.ArgumentParser(description='åœ¨çº¿TCNæ£€æµ‹')
    parser.add_argument('--ckpt', type=str, required=True, help='TCNæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_path', type=str, help='æµ‹è¯•æ•°æ®è·¯å¾„ï¼ˆç”¨äºæ¨¡æ‹Ÿï¼‰')
    parser.add_argument('--output_dir', type=str, default='./outputs/online', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--buffer_size', type=int, default=120, help='ç¼“å†²åŒºå¤§å°ï¼ˆåˆ†é’Ÿï¼‰')
    parser.add_argument('--threshold', type=float, default=0.5, help='æ£€æµ‹é˜ˆå€¼')
    parser.add_argument('--min_duration', type=int, default=3, help='æœ€å°æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰')
    parser.add_argument('--speed_factor', type=float, default=60.0, help='æ¨¡æ‹Ÿé€Ÿåº¦å› å­')
    parser.add_argument('--max_samples', type=int, default=1000, help='æœ€å¤§å¤„ç†æ ·æœ¬æ•°')
    parser.add_argument('--device', type=str, default='auto', help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--quiet', action='store_true', help='é™é»˜æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆ›å»ºåœ¨çº¿æ£€æµ‹ç³»ç»Ÿ
    detection_system = OnlineDetectionSystem(
        model_path=args.ckpt,
        config_path=args.config,
        device=args.device,
        buffer_size=args.buffer_size,
        detection_threshold=args.threshold,
        min_duration=args.min_duration,
        event_callback=event_handler if not args.quiet else None
    )
    
    if args.data_path:
        # ä½¿ç”¨æ•°æ®æ–‡ä»¶è¿›è¡Œæ¨¡æ‹Ÿ
        print(f"å¼€å§‹æ¨¡æ‹Ÿåœ¨çº¿æ£€æµ‹ï¼Œæ•°æ®æº: {args.data_path}")
        
        # åˆ›å»ºæ•°æ®æ¨¡æ‹Ÿå™¨
        simulator = RealTimeDataSimulator(
            data_path=args.data_path,
            feature_extractor=detection_system.feature_extractor,
            speed_factor=args.speed_factor
        )
        
        # å¤„ç†è®¡æ•°å™¨
        sample_count = 0
        results = []
        
        def data_callback(sample: Dict[str, Any]):
            nonlocal sample_count
            
            # å¤„ç†æ ·æœ¬
            result = detection_system.process_sample(sample)
            results.append(result)
            
            sample_count += 1
            
            # æ˜¾ç¤ºè¿›åº¦
            if not args.quiet and sample_count % 10 == 0:
                stats = detection_system.get_statistics()
                print(f"\rå¤„ç†æ ·æœ¬: {sample_count}/{args.max_samples}, "
                      f"äº‹ä»¶: {stats['total_events']}, "
                      f"é€Ÿåº¦: {stats['samples_per_minute']:.1f} æ ·æœ¬/åˆ†é’Ÿ", end='')
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°
            if sample_count >= args.max_samples:
                simulator.stop_streaming()
        
        # å¼€å§‹æµå¼å¤„ç†
        try:
            simulator.start_streaming(data_callback)
            
            # ç­‰å¾…å¤„ç†å®Œæˆ
            while simulator.is_running and sample_count < args.max_samples:
                time.sleep(1)
            
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨åœæ­¢...")
            simulator.stop_streaming()
        
        # ä¿å­˜ç»“æœ
        results_path = os.path.join(args.output_dir, 'detection_results.json')
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_path = os.path.join(args.output_dir, 'statistics.json')
        detection_system.save_statistics(stats_path)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        final_stats = detection_system.get_statistics()
        print(f"\n\nğŸ“Š æ£€æµ‹å®Œæˆç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {final_stats['total_samples']}")
        print(f"   æ€»äº‹ä»¶æ•°: {final_stats['total_events']}")
        print(f"   è¿è¡Œæ—¶é—´: {final_stats['runtime_str']}")
        print(f"   å¤„ç†é€Ÿåº¦: {final_stats['samples_per_minute']:.1f} æ ·æœ¬/åˆ†é’Ÿ")
        print(f"\nğŸ“ ç»“æœä¿å­˜åˆ°: {args.output_dir}")
        
    else:
        # å®æ—¶æ¨¡å¼ï¼ˆç­‰å¾…å¤–éƒ¨æ•°æ®è¾“å…¥ï¼‰
        print("è¿›å…¥å®æ—¶æ£€æµ‹æ¨¡å¼ï¼Œç­‰å¾…æ•°æ®è¾“å…¥...")
        print("æŒ‰ Ctrl+C é€€å‡º")
        
        try:
            while True:
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä»ä¼ æ„Ÿå™¨æˆ–æ•°æ®æµä¸­è·å–æ•°æ®
                # è¿™é‡Œåªæ˜¯ä¸€ä¸ªç¤ºä¾‹å¾ªç¯
                time.sleep(1)
                
        except KeyboardInterrupt:
            print("\næ£€æµ‹ç³»ç»Ÿå·²åœæ­¢")
            
            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
            stats_path = os.path.join(args.output_dir, 'statistics.json')
            detection_system.save_statistics(stats_path)

if __name__ == '__main__':
    main()