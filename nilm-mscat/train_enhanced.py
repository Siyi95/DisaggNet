#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆè®­ç»ƒè„šæœ¬
æ”¯æŒè‡ªé€‚åº”è®¾å¤‡æ£€æµ‹ã€TensorBoardå¯è§†åŒ–å’Œå¯è§£é‡Šæ€§åˆ†æ
"""

import os
import sys
import argparse
import yaml
import torch
import torch.nn as nn
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, Optional, List
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.datamodule import AMPds2DataModule
from src.train_pretrain import MaskedReconstructionModel
from src.train_finetune import NILMModel

def detect_device():
    """
    è‡ªé€‚åº”æ£€æµ‹å¯ç”¨çš„è®¡ç®—è®¾å¤‡
    ä¼˜å…ˆçº§: CUDA > MPS > CPU
    """
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        device_count = torch.cuda.device_count()
        print(f"ğŸš€ æ£€æµ‹åˆ°CUDAè®¾å¤‡: {device_name} (å…±{device_count}ä¸ªGPU)")
        return 'gpu', device_count
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("ğŸ æ£€æµ‹åˆ°MPSè®¾å¤‡ (Apple Silicon)")
        return 'mps', 1
    else:
        print("ğŸ’» ä½¿ç”¨CPUè®¾å¤‡")
        return 'cpu', 1

class EnhancedVisualizationCallback(pl.Callback):
    """
    å¢å¼ºçš„å¯è§†åŒ–å›è°ƒå‡½æ•°
    æä¾›è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¯è§£é‡Šæ€§åˆ†æå’Œå¯è§†åŒ–
    """
    
    def __init__(self, log_dir: str, visualize_every_n_epochs: int = 10):
        super().__init__()
        self.log_dir = Path(log_dir)
        self.visualize_every_n_epochs = visualize_every_n_epochs
        self.vis_dir = self.log_dir / 'visualizations'
        self.vis_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®matplotlibæ ·å¼
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
    
    def on_validation_epoch_end(self, trainer, pl_module):
        """éªŒè¯è½®æ¬¡ç»“æŸæ—¶çš„å¯è§†åŒ–"""
        if trainer.current_epoch % self.visualize_every_n_epochs == 0:
            self._visualize_training_progress(trainer, pl_module)
            self._visualize_attention_weights(trainer, pl_module)
            self._visualize_feature_importance(trainer, pl_module)
    
    def _visualize_training_progress(self, trainer, pl_module):
        """å¯è§†åŒ–è®­ç»ƒè¿›åº¦"""
        try:
            # è·å–è®­ç»ƒå†å²
            metrics = trainer.logged_metrics
            
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'Training Progress - Epoch {trainer.current_epoch}', fontsize=16)
            
            # æŸå¤±æ›²çº¿
            if 'train_loss' in metrics and 'val_loss' in metrics:
                axes[0, 0].plot(range(trainer.current_epoch + 1), 
                               [metrics.get('train_loss', 0)] * (trainer.current_epoch + 1), 
                               label='Train Loss', alpha=0.7)
                axes[0, 0].plot(range(trainer.current_epoch + 1), 
                               [metrics.get('val_loss', 0)] * (trainer.current_epoch + 1), 
                               label='Val Loss', alpha=0.7)
                axes[0, 0].set_title('Loss Curves')
                axes[0, 0].set_xlabel('Epoch')
                axes[0, 0].set_ylabel('Loss')
                axes[0, 0].legend()
                axes[0, 0].grid(True, alpha=0.3)
            
            # å­¦ä¹ ç‡æ›²çº¿
            if 'lr-AdamW' in metrics:
                axes[0, 1].plot(range(trainer.current_epoch + 1), 
                               [metrics.get('lr-AdamW', 0)] * (trainer.current_epoch + 1))
                axes[0, 1].set_title('Learning Rate')
                axes[0, 1].set_xlabel('Epoch')
                axes[0, 1].set_ylabel('LR')
                axes[0, 1].grid(True, alpha=0.3)
            
            # MAEæŒ‡æ ‡
            if 'val_MAE_total' in metrics:
                axes[1, 0].bar(['Total MAE'], [metrics.get('val_MAE_total', 0)])
                axes[1, 0].set_title('Validation MAE')
                axes[1, 0].set_ylabel('MAE')
                axes[1, 0].grid(True, alpha=0.3)
            
            # è®¾å¤‡çº§åˆ«MAE
            device_maes = {k: v for k, v in metrics.items() if 'MAE_' in k and k != 'val_MAE_total'}
            if device_maes:
                device_names = [k.replace('val_MAE_', '') for k in device_maes.keys()]
                mae_values = list(device_maes.values())
                axes[1, 1].bar(device_names, mae_values)
                axes[1, 1].set_title('Device-level MAE')
                axes[1, 1].set_ylabel('MAE')
                axes[1, 1].tick_params(axis='x', rotation=45)
                axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            save_path = self.vis_dir / f'training_progress_epoch_{trainer.current_epoch}.png'
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            # è®°å½•åˆ°TensorBoard
            if hasattr(trainer.logger, 'experiment'):
                trainer.logger.experiment.add_figure(
                    'Training/Progress', fig, trainer.current_epoch
                )
                
        except Exception as e:
            print(f"âš ï¸ è®­ç»ƒè¿›åº¦å¯è§†åŒ–å¤±è´¥: {e}")
    
    def _visualize_attention_weights(self, trainer, pl_module):
        """å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡"""
        try:
            if hasattr(pl_module, 'encoder') and hasattr(pl_module.encoder, 'local_branch'):
                # è·å–ä¸€ä¸ªéªŒè¯æ‰¹æ¬¡
                val_dataloader = trainer.val_dataloaders[0] if trainer.val_dataloaders else None
                if val_dataloader is None:
                    return
                
                batch = next(iter(val_dataloader))
                x = batch['features'][:1]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
                timestamps = batch.get('timestamps', None)
                if timestamps is not None:
                    timestamps = timestamps[:1]
                
                # å‰å‘ä¼ æ’­è·å–æ³¨æ„åŠ›æƒé‡
                pl_module.eval()
                with torch.no_grad():
                    if timestamps is not None:
                        _ = pl_module.encoder(x, timestamps)
                    else:
                        _ = pl_module.encoder(x)
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–ä»£ç 
                # éœ€è¦æ ¹æ®æ¨¡å‹ç»“æ„è°ƒæ•´
                
        except Exception as e:
            print(f"âš ï¸ æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–å¤±è´¥: {e}")
    
    def _visualize_feature_importance(self, trainer, pl_module):
        """å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§"""
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç‰¹å¾é‡è¦æ€§åˆ†æ
            # ä¾‹å¦‚æ¢¯åº¦åˆ†æã€SHAPå€¼ç­‰
            pass
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–å¤±è´¥: {e}")

def create_enhanced_trainer(config: Dict[str, Any], 
                          output_dir: str,
                          accelerator: str,
                          devices: int) -> pl.Trainer:
    """
    åˆ›å»ºå¢å¼ºçš„è®­ç»ƒå™¨
    """
    # TensorBoardæ—¥å¿—è®°å½•å™¨
    logger = TensorBoardLogger(
        save_dir=output_dir,
        name='enhanced_logs',
        version=None,
        log_graph=True  # è®°å½•è®¡ç®—å›¾
    )
    
    # å›è°ƒå‡½æ•°
    callbacks = [
        ModelCheckpoint(
            dirpath=os.path.join(output_dir, 'checkpoints'),
            filename='best_model_{epoch:02d}_{val_loss:.4f}',
            monitor='val_loss',
            mode='min',
            save_top_k=3,
            save_last=True,
            save_weights_only=False
        ),
        EarlyStopping(
            monitor='val_loss',
            patience=config.get('early_stopping_patience', 15),
            mode='min',
            verbose=True
        ),
        LearningRateMonitor(
            logging_interval='step',
            log_momentum=True
        ),
        EnhancedVisualizationCallback(
            log_dir=output_dir,
            visualize_every_n_epochs=config.get('visualize_every_n_epochs', 5)
        )
    ]
    
    # è®­ç»ƒå™¨é…ç½®
    trainer_config = {
        'max_epochs': config.get('max_epochs', 100),
        'accelerator': accelerator,
        'devices': devices if accelerator != 'cpu' else 'auto',
        'precision': config.get('precision', '16-mixed'),
        'logger': logger,
        'callbacks': callbacks,
        'gradient_clip_val': config.get('gradient_clip_val', 1.0),
        'accumulate_grad_batches': config.get('accumulate_grad_batches', 1),
        'val_check_interval': config.get('val_check_interval', 1.0),
        'log_every_n_steps': config.get('log_every_n_steps', 50),
        'enable_progress_bar': True,
        'enable_model_summary': True
    }
    
    # å¦‚æœä½¿ç”¨CPUï¼Œç§»é™¤precisionè®¾ç½®
    if accelerator == 'cpu':
        trainer_config.pop('precision', None)
    
    return pl.Trainer(**trainer_config)

def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def main():
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆMS-CATè®­ç»ƒè„šæœ¬')
    parser.add_argument('--mode', type=str, choices=['pretrain', 'finetune'], 
                       required=True, help='è®­ç»ƒæ¨¡å¼')
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_path', type=str, help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./outputs', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--pretrain_ckpt', type=str, help='é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--resume_from', type=str, help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
    parser.add_argument('--force_cpu', action='store_true', help='å¼ºåˆ¶ä½¿ç”¨CPU')
    parser.add_argument('--epochs', type=int, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning_rate', type=float, help='å­¦ä¹ ç‡')
    
    args = parser.parse_args()
    
    # æ£€æµ‹è®¾å¤‡
    if args.force_cpu:
        accelerator, devices = 'cpu', 1
        print("ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡")
    else:
        accelerator, devices = detect_device()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # è¦†ç›–é…ç½®ä¸­çš„å‚æ•°
    if args.data_path:
        config['data']['data_path'] = args.data_path
    if args.epochs:
        config['max_epochs'] = args.epochs
    if args.batch_size:
        config['data']['batch_size'] = args.batch_size
    if args.learning_rate:
        config['optimizer']['lr'] = args.learning_rate
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join(args.output_dir, args.mode)
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    pl.seed_everything(config.get('seed', 42))
    
    print(f"ğŸ¯ å¼€å§‹{args.mode}è®­ç»ƒ...")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"âš™ï¸ è®¾å¤‡é…ç½®: {accelerator} (è®¾å¤‡æ•°: {devices})")
    
    # æ•°æ®æ¨¡å—
    data_module = AMPds2DataModule(**config['data'])
    data_module.setup('fit')
    
    # è·å–ç‰¹å¾ç»´åº¦
    input_dim = data_module.get_feature_dim()
    print(f"ğŸ“Š è¾“å…¥ç‰¹å¾ç»´åº¦: {input_dim}")
    
    # åˆ›å»ºæ¨¡å‹
    model_config = config['model']
    model_config['input_dim'] = input_dim
    
    if args.mode == 'pretrain':
        model = MaskedReconstructionModel(**model_config)
        print("ğŸ—ï¸ åˆ›å»ºé¢„è®­ç»ƒæ¨¡å‹")
    else:  # finetune
        # è·å–è®¾å¤‡ä¿¡æ¯
        device_names = data_module.get_device_names()
        num_devices = len(device_names)
        model_config['num_devices'] = num_devices
        model_config['device_names'] = device_names
        
        model = NILMModel(**model_config)
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if args.pretrain_ckpt:
            print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {args.pretrain_ckpt}")
            pretrain_model = MaskedReconstructionModel.load_from_checkpoint(args.pretrain_ckpt)
            model.load_pretrained_encoder(pretrain_model.encoder)
        
        print(f"ğŸ—ï¸ åˆ›å»ºå¾®è°ƒæ¨¡å‹ (è®¾å¤‡æ•°: {num_devices})")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = create_enhanced_trainer(config, output_dir, accelerator, devices)
    
    # å¼€å§‹è®­ç»ƒ
    if args.resume_from:
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume_from}")
        trainer.fit(model, data_module, ckpt_path=args.resume_from)
    else:
        trainer.fit(model, data_module)
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(output_dir, f'final_model_{args.mode}.ckpt')
    trainer.save_checkpoint(final_model_path)
    print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {final_model_path}")
    
    # æ‰“å°TensorBoardå¯åŠ¨å‘½ä»¤
    print(f"\nğŸ“ˆ æŸ¥çœ‹è®­ç»ƒæ—¥å¿—:")
    print(f"tensorboard --logdir {output_dir}")
    print(f"ç„¶ååœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://localhost:6006")

if __name__ == '__main__':
    main()